{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from autogluon.timeseries.metrics import TimeSeriesScorer\n",
    "from autogluon.timeseries import TimeSeriesDataFrame, TimeSeriesPredictor\n",
    "from autogluon.timeseries.models import PatchTSTModel, TemporalFusionTransformerModel\n",
    "from plotnine import *\n",
    "from statsmodels.tsa.arima_process import ArmaProcess\n",
    "from typing import Any, Dict, Type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill in the function below. Assume that\n",
    "- The `target` column of `test_data` contains the data.\n",
    "- `predictions` contains predictions for the last `prediction_length` observations in `test_data`.\n",
    "- The next-to-last column of `predictions` contains lower bounds for prediction intervals and the last column contains upper bounds.\n",
    "\n",
    "The function should return the coverage, i.e., the proportion of observations that fall into the corresponding prediction interval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def help_calc_coverages_for_1_window(\n",
    "        target: str,\n",
    "        test_data: TimeSeriesDataFrame,\n",
    "        prediction_length: int,\n",
    "        predictions: TimeSeriesDataFrame\n",
    "    ) -> float:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill in the function below. Assume that\n",
    "\n",
    "- The `timestamp_col` column of `window_data` contains observation times and the `target` column contains observation values.\n",
    "- The last `prediction_length` observations in `window_data` are test observations and the prior observations are training observations.\n",
    "- Predictions are to be evaluated using `eval_metric`.\n",
    "- Level-`ci_level` prediction intervals are needed. `ci_level` could be 0.95, for example.\n",
    "- The training of any one model cannot take longer than `time_limit` seconds.\n",
    "- The models to be used are specified in `hyperparameters`. For example, `hyperparameters` could equal `{\"AutoARIMA\": {}}`.\n",
    "\n",
    "The function should compute the test set coverage for each model in `hyperparameters`. It should return a `DataFrame` with one row for each model. The `DataFrame`'s columns should be `test_start_time`, `test_end_time`, `model`, and `coverage`, in that order. Use `help_calc_coverages_for_1_window` to compute the coverage for each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_coverages_for_1_window(\n",
    "        window_data: pd.DataFrame,\n",
    "        timestamp_col: str,\n",
    "        target: str | None,\n",
    "        prediction_length: int,\n",
    "        eval_metric: str | TimeSeriesScorer | None,\n",
    "        ci_level: float,\n",
    "        time_limit: int | None,\n",
    "        hyperparameters: Dict[str | Type, Any]\n",
    "    ) -> float:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill in the function below. Assume that\n",
    "\n",
    "- The `timestamp_col` column of `data` contains observation times and the `target` column contains observation values. Windows are to be carved out of `data`, with one or more time series models being trained and tested on each window.\n",
    "- The first `train_size` observations in a window are training observations and the last `prediction_length` observations are test observations.\n",
    "- The starting indices of consecutive windows differ by `stride`.\n",
    "- Predictions are to be evaluated using `eval_metric`.\n",
    "- Level-`ci_level` prediction intervals are needed. `ci_level` could be 0.95, for example.\n",
    "- The training of any one model cannot take longer than `time_limit` seconds.\n",
    "- The models to be used are specified in `hyperparameters`. For example, `hyperparameters` could equal `{\"AutoARIMA\": {}}`.\n",
    "\n",
    "The function should compute the test set coverages for the models in `hyperparameters` on all of the windows. It should return a `DataFrame` with one row for each pair of window and model. The `DataFrame`'s columns should be `test_start_time`, `test_end_time`, `model`, and `coverage`, in that order. Use `calc_coverages_for_1_window` to compute the coverages for each window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_coverages(\n",
    "        data: pd.DataFrame,\n",
    "        train_size: int,\n",
    "        prediction_length: int,\n",
    "        stride: int,\n",
    "        timestamp_col: str,\n",
    "        target: str | None,\n",
    "        eval_metric: str | TimeSeriesScorer | None,\n",
    "        ci_level: float,\n",
    "        time_limit: int | None,\n",
    "        hyperparameters: Dict[str | Type, Any]\n",
    "    ) -> pd.DataFrame:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we write a function, we ought to test it to ensure that it works. When a function operates on data, one way to test it is to simulate data from a model and verify that the function returns what it should for the simulated data.\n",
    "\n",
    "One of the simplest time series models is the AR(1) model, the autoregressive model of order 1. It is defined by the equation\n",
    "$$\n",
    "Y_t = \\phi Y_{t - 1} + \\epsilon_t, \\ t \\in \\mathbb{Z},\n",
    "$$\n",
    "where the $\\epsilon_t$'s are uncorrelated random variables with common mean zero and common variance $\\sigma^2$, and $\\epsilon_t$ is independent of $Y_{t - 1}, Y_{t - 2}, Y_{t - 3}, \\ldots$. The $\\epsilon_t$'s are called *innovations*. For a Gaussian AR(1) model, the innovations are $N(0, \\sigma^2)$ random variables.\n",
    "\n",
    "One desirable property of a time series model is *stationarity*. If the model is stationary, then the mean and variance of $Y_t$ don't depend on $t$. Also, the covariance between $Y_t$ and $Y_u$ depends on $t$ and $u$ only through $|t - u|$, so we can talk about *the* covariance at lag $\\ell$, $\\text{Cov}(Y_t, Y_{t + \\ell})$, which doesn't depend on $t$. The covariances at the various lags are called *autocovariances*. It can be shown that the AR(1) model is stationary if and only if $|\\phi| < 1$.\n",
    "\n",
    "Define a function `simulate_ar1` that draws a sample of size $n$ from a Gaussian AR(1) model with coefficient $\\phi$ and innovation standard deviation $\\sigma$.\n",
    "- Check whether $|\\phi| < 1$ - raise a `ValueError` if it isn't.\n",
    "- Use `statsmodels.tsa.arima_process.ArmaProcess` to create an object representing the time series.\n",
    "- Use the object's `generate_sample` method to generate a sample of size $n$.\n",
    "- Return the sample in a `DataFrame` with two columns:\n",
    "    - `timestamp`, which contains a sequence of times that starts at `Timestamp(\"2020-01-01 00:00:00\")` and has a one-minute step size.\n",
    "    - `target`, which contains the sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_ar1(phi: float, sigma: float, n: int) -> pd.DataFrame:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a model of the form $Y = f(X) + \\epsilon$, where $X$ and $\\epsilon$ are independent, the *signal-to-noise ratio (SNR)* is defined as\n",
    "$$\n",
    "\\frac{\\text{Var}(f(X))}{\\text{Var}(\\epsilon)}.\n",
    "$$\n",
    "The fraction of the variance of $Y$ explained by the signal $f(X)$, which we'll call the FVE, is\n",
    "$$\n",
    "\\frac{\\text{Var}(f(X))}{\\text{Var}(Y)} = \\frac{\\text{Var}(f(X))}{\\text{Var}(f(X)) + \\text{Var}(\\epsilon)} = \\frac{\\text{SNR}}{\\text{SNR} + 1}.\n",
    "$$\n",
    "\n",
    "For a stationary AR(1) model, derive expressions for the SNR and FVE. Then define a function `calc_phi_from_fve` that takes an FVE and returns the nonnegative $\\phi$ that yields that FVE. The function should raise a `ValueError` if the FVE isn't in $[0, 1)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_phi_from_fve(fve: float) -> float:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the functions have been filled in, run the code below to verify that the coverage functions work. Since `ci_level` equals 0.95, the coverage you get should be 0.95."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fve = 0.9\n",
    "phi = calc_phi_from_fve(fve)\n",
    "sigma = 1\n",
    "n = 1000\n",
    "\n",
    "window_data = simulate_ar1(phi, sigma, n)\n",
    "timestamp_col = \"timestamp\"\n",
    "target = \"target\"\n",
    "prediction_length = 100\n",
    "eval_metric = \"RMSE\"\n",
    "ci_level = 0.95\n",
    "time_limit = 60\n",
    "hyperparameters = {\"AutoARIMA\": {}}\n",
    "\n",
    "calc_coverages_for_1_window(window_data, timestamp_col, target, prediction_length, eval_metric, ci_level, time_limit, hyperparameters)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
