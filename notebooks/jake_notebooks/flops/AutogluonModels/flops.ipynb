{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogluon.timeseries import TimeSeriesPredictor\n",
    "import os\n",
    "import torch\n",
    "from torchinfo import summary\n",
    "import pickle\n",
    "import gluonts.torch.model.patch_tst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "wd = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_predictor_pth = os.path.join(wd, \"ag-20250317_170713\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'autogluon.timeseries.predictor.TimeSeriesPredictor'>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "predictor = TimeSeriesPredictor.load(model_predictor_pth)\n",
    "print(type(predictor))  # List of trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__annotations__', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_ag_params', '_apply_conformalization', '_apply_temperature_scaling', '_calculate_total_resources', '_check_fit_params', '_class_tags', '_compile', '_compiler', '_compute_fit_metadata', '_compute_permutation_importance', '_convert_proba_to_unified_form', '_covariate_regressor_fit_time_fraction', '_create_covariate_regressor', '_create_covariate_scaler', '_create_target_scaler', '_default_compiler', '_estimate_memory_usage', '_estimate_memory_usage_static', '_feature_metadata', '_features', '_features_internal', '_fit', '_fit_metadata', '_get_ag_params', '_get_child_aux_val', '_get_class_tags', '_get_compiler', '_get_default_ag_args', '_get_default_ag_args_ensemble', '_get_default_auxiliary_params', '_get_default_hpo_executor', '_get_default_resources', '_get_default_searchspace', '_get_default_stopping_metric', '_get_hpo_backend', '_get_hpo_train_fn_kwargs', '_get_input_types', '_get_maximum_resources', '_get_memory_size', '_get_model_base', '_get_model_params', '_get_model_params_static', '_get_params', '_get_search_space', '_get_tags', '_hyperparameter_tune', '_infer_feature_metadata', '_infer_num_classes', '_infer_problem_type', '_init_misc', '_init_params', '_init_params_aux', '_init_user_params', '_initialize', '_is_features_in_same_as_ex', '_is_fit_metadata_registered', '_is_gpu_available', '_is_initialized', '_make_learning_curves', '_more_tags', '_oof_filename', '_oof_predictions', '_path_v2', '_post_fit', '_predict', '_predict_n_size', '_predict_proba', '_predict_proba_internal', '_preprocess', '_preprocess_fit_args', '_preprocess_fit_resources', '_preprocess_nonadaptive', '_preprocess_set_features', '_process_user_provided_resource_requirement_to_calculate_total_resource_when_ensemble', '_register_fit_metadata', '_score_with_predictions', '_set_default_auxiliary_params', '_set_default_param_value', '_set_default_params', '_update_feature_metadata', '_user_params', '_user_params_aux', '_valid_compilers', '_validate_fit_memory_usage', '_validate_fit_resources', '_validate_params', '_validate_params_aux', 'allowed_hyperparameters', 'can_compile', 'can_estimate_memory_usage_static', 'can_estimate_memory_usage_static_child', 'can_fit', 'can_infer', 'can_predict_proba', 'compile', 'compile_time', 'compute_feature_importance', 'conformalize', 'convert_to_refit_full_template', 'convert_to_refit_full_via_copy', 'convert_to_template', 'covariate_regressor', 'covariate_scaler', 'create_contexts', 'default_max_time_limit_ratio', 'delete_from_disk', 'disk_usage', 'estimate_memory_usage', 'estimate_memory_usage_child', 'estimate_memory_usage_static', 'estimate_memory_usage_static_child', 'eval_metric', 'eval_metric_seasonal_period', 'feature_metadata', 'features', 'fit', 'fit_num_cpus', 'fit_num_cpus_child', 'fit_num_gpus', 'fit_num_gpus_child', 'fit_time', 'freq', 'get_child_model', 'get_compiler_name', 'get_features', 'get_fit_metadata', 'get_info', 'get_memory_size', 'get_minimum_resources', 'get_oof_predictions', 'get_params', 'get_params_aux_info', 'get_trained_params', 'get_user_params', 'hyperparameter_tune', 'info_per_val_window', 'initialize', 'is_fit', 'is_initialized', 'is_valid', 'learning_curve_file_name', 'load', 'load_info', 'load_learning_curves', 'load_oof_predictions', 'metadata', 'model', 'model_base', 'model_base_type', 'model_file_name', 'model_info_json_name', 'model_info_name', 'most_recent_model', 'most_recent_model_folder', 'must_drop_median', 'name', 'nondefault_params', 'normalize_pred_probas', 'num_classes', 'params', 'params_aux', 'params_trained', 'path', 'path_root', 'path_suffix', 'persist', 'predict', 'predict_1_time', 'predict_from_proba', 'predict_n_size', 'predict_n_time_per_row', 'predict_proba', 'predict_time', 'prediction_length', 'preprocess', 'problem_type', 'quantile_levels', 'record_predict_info', 'reduce_memory_size', 'rename', 'reset_metrics', 'save', 'save_info', 'save_learning_curves', 'saved_learning_curves', 'score', 'score_and_cache_oof', 'score_with_y_pred_proba', 'set_contexts', 'stopping_metric', 'supports_known_covariates', 'supports_past_covariates', 'supports_static_features', 'target', 'target_scaler', 'val_score', 'validate_fit_resources']\n"
     ]
    }
   ],
   "source": [
    "model_name = \"TemporalFusionTransformer\"  # or \"NeuralNetTorch\"\n",
    "model = predictor._trainer.load_model(model_name)\n",
    "print(dir(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "{'max_epochs': 2}\n"
     ]
    }
   ],
   "source": [
    "nn_model = predictor._trainer.load_model(\"TemporalFusionTransformer\").model_base\n",
    "print((nn_model.gts_predictor))\n",
    "print(nn_model.get_trained_params())\n",
    "# input_size = (1, 100, 1)\n",
    "\n",
    "# summary(nn_model, input_size=input_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['_ag_params', '_apply_conformalization', '_apply_temperature_scaling', '_calculate_total_resources', '_check_fit_params', '_class_tags', '_compile', '_compiler', '_compute_fit_metadata', '_compute_permutation_importance', '_convert_proba_to_unified_form', '_covariate_regressor_fit_time_fraction', '_create_covariate_regressor', '_create_covariate_scaler', '_create_target_scaler', '_default_compiler', '_deferred_init_params_aux', '_dummy_gluonts_freq', '_estimate_memory_usage', '_estimate_memory_usage_static', '_feature_metadata', '_features', '_features_internal', '_fit', '_fit_metadata', '_get_ag_params', '_get_callbacks', '_get_child_aux_val', '_get_class_tags', '_get_compiler', '_get_default_ag_args', '_get_default_ag_args_ensemble', '_get_default_auxiliary_params', '_get_default_hpo_executor', '_get_default_params', '_get_default_resources', '_get_default_searchspace', '_get_default_stopping_metric', '_get_estimator', '_get_estimator_class', '_get_estimator_init_args', '_get_hpo_backend', '_get_hpo_train_fn_kwargs', '_get_input_types', '_get_maximum_resources', '_get_memory_size', '_get_model_base', '_get_model_params', '_get_model_params_static', '_get_params', '_get_search_space', '_get_tags', '_gluonts_forecasts_to_data_frame', '_hyperparameter_tune', '_infer_feature_metadata', '_infer_num_classes', '_infer_problem_type', '_init_misc', '_init_params', '_init_params_aux', '_init_user_params', '_initialize', '_is_features_in_same_as_ex', '_is_fit_metadata_registered', '_is_gpu_available', '_is_initialized', '_make_learning_curves', '_more_tags', '_ohe_generator_known', '_ohe_generator_past', '_oof_filename', '_oof_predictions', '_path_v2', '_post_fit', '_predict', '_predict_gluonts_forecasts', '_predict_n_size', '_predict_proba', '_predict_proba_internal', '_preprocess', '_preprocess_fit_args', '_preprocess_fit_resources', '_preprocess_nonadaptive', '_preprocess_set_features', '_process_user_provided_resource_requirement_to_calculate_total_resource_when_ensemble', '_register_fit_metadata', '_score_with_predictions', '_set_default_auxiliary_params', '_set_default_param_value', '_set_default_params', '_stack_distribution_forecasts', '_stack_quantile_forecasts', '_stack_sample_forecasts', '_to_gluonts_dataset', '_update_feature_metadata', '_user_params', '_user_params_aux', '_valid_compilers', '_validate_fit_memory_usage', '_validate_fit_resources', '_validate_params', '_validate_params_aux', 'allowed_hyperparameters', 'callbacks', 'can_compile', 'can_estimate_memory_usage_static', 'can_estimate_memory_usage_static_child', 'can_fit', 'can_infer', 'can_predict_proba', 'compile', 'compile_time', 'compute_feature_importance', 'conformalize', 'convert_to_refit_full_template', 'convert_to_refit_full_via_copy', 'convert_to_template', 'covariate_regressor', 'covariate_scaler', 'create_contexts', 'default_max_time_limit_ratio', 'default_num_samples', 'delete_from_disk', 'disk_usage', 'estimate_memory_usage', 'estimate_memory_usage_child', 'estimate_memory_usage_static', 'estimate_memory_usage_static_child', 'eval_metric', 'eval_metric_seasonal_period', 'feat_dynamic_cat_cardinality', 'feat_static_cat_cardinality', 'feature_metadata', 'features', 'fit', 'fit_num_cpus', 'fit_num_cpus_child', 'fit_num_gpus', 'fit_num_gpus_child', 'fit_time', 'freq', 'get_compiler_name', 'get_features', 'get_fit_metadata', 'get_info', 'get_memory_size', 'get_minimum_resources', 'get_oof_predictions', 'get_params', 'get_params_aux_info', 'get_trained_params', 'get_user_params', 'gluonts_model_path', 'gts_predictor', 'hyperparameter_tune', 'initialize', 'is_fit', 'is_initialized', 'is_valid', 'learning_curve_file_name', 'load', 'load_info', 'load_learning_curves', 'load_oof_predictions', 'metadata', 'model', 'model_file_name', 'model_info_json_name', 'model_info_name', 'must_drop_median', 'name', 'negative_data', 'nondefault_params', 'normalize_pred_probas', 'num_classes', 'num_feat_dynamic_cat', 'num_feat_dynamic_real', 'num_feat_static_cat', 'num_feat_static_real', 'num_past_feat_dynamic_cat', 'num_past_feat_dynamic_real', 'params', 'params_aux', 'params_trained', 'past_feat_dynamic_cat_cardinality', 'path', 'path_root', 'path_suffix', 'persist', 'predict', 'predict_1_time', 'predict_from_proba', 'predict_n_size', 'predict_n_time_per_row', 'predict_proba', 'predict_time', 'prediction_length', 'preprocess', 'problem_type', 'quantile_levels', 'record_predict_info', 'reduce_memory_size', 'rename', 'reset_metrics', 'save', 'save_info', 'save_learning_curves', 'saved_learning_curves', 'score', 'score_and_cache_oof', 'score_with_y_pred_proba', 'set_contexts', 'stopping_metric', 'supports_cat_covariates', 'supports_known_covariates', 'supports_past_covariates', 'supports_static_features', 'target', 'target_scaler', 'val_score', 'validate_fit_resources']\n"
     ]
    }
   ],
   "source": [
    "print([attr for attr in dir(nn_model) if not attr.startswith(\"__\")])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/jakegwinn/Documents/umich/Y5S2/urps/urps_2025/notebooks/jake_notebooks/flops/AutogluonModels/ag-20250317_170713/models/trainer.pkl\n"
     ]
    }
   ],
   "source": [
    "models = os.path.join(os.path.join(wd, \"ag-20250317_170713\"), \"models\")\n",
    "TFT = os.path.join(models, \"TemporalFusionTransformer\")\n",
    "\n",
    "mod_pik = os.path.join(models, \"trainer.pkl\")\n",
    "print(mod_pik)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'autogluon.timeseries.models.gluonts.torch.tft'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[343], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mautogluon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtimeseries\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgluonts\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtft\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TemporalFusionTransformerModel\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpickle\u001b[39;00m\n\u001b[1;32m      4\u001b[0m model_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(TFT, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# Adjust based on actual path\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'autogluon.timeseries.models.gluonts.torch.tft'"
     ]
    }
   ],
   "source": [
    "# from autogluon.timeseries.models.gluonts.torch.tft import TemporalFusionTransformerModel\n",
    "# import pickle\n",
    "\n",
    "# model_path = os.path.join(TFT, \"model.pkl\")  # Adjust based on actual path\n",
    "\n",
    "# # Load with pickle (since AutoGluon likely saved it this way)\n",
    "# with open(model_path, \"rb\") as f:\n",
    "#     autogluon_model = pickle.load(f)\n",
    "\n",
    "# print(type(autogluon_model))  # Check if it's the TFT model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = gluonts.torch.model.patch_tst.PatchTSTModel(context_length=96, prediction_length=1, patch_len=16, stride=8,d_model=32, nhead=4, num_encoder_layers=2, scaling=\"mean\",activation=\"relu\", dim_feedforward=32, dropout=0.1, norm_first=False, padding_patch=\"end\", num_feat_dynamic_real=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fvcore.nn import FlopCountAnalysis\n",
    "\n",
    "# flops = FlopCountAnalysis(model, torch.randn(1, 100, 1))\n",
    "# print(flops.total())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class WrappedForecastModel(nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, seq_len, feat_dim = x.shape\n",
    "\n",
    "        # Dummy values for required model inputs\n",
    "        return self.model(\n",
    "            past_target=x.squeeze(-1),\n",
    "            past_observed_values=torch.ones_like(x.squeeze(-1)),  # Typically a mask of same shape\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsupported operator aten::ones_like encountered 1 time(s)\n",
      "Unsupported operator aten::mul encountered 9 time(s)\n",
      "Unsupported operator aten::abs encountered 2 time(s)\n",
      "Unsupported operator aten::sum encountered 4 time(s)\n",
      "Unsupported operator aten::div encountered 5 time(s)\n",
      "Unsupported operator aten::where encountered 1 time(s)\n",
      "Unsupported operator aten::pad encountered 1 time(s)\n",
      "Unsupported operator aten::unfold encountered 1 time(s)\n",
      "Unsupported operator aten::log1p encountered 1 time(s)\n",
      "Unsupported operator aten::log encountered 1 time(s)\n",
      "Unsupported operator aten::add encountered 7 time(s)\n",
      "Unsupported operator aten::embedding encountered 1 time(s)\n",
      "Unsupported operator aten::unflatten encountered 2 time(s)\n",
      "Unsupported operator aten::scaled_dot_product_attention encountered 2 time(s)\n",
      "Unsupported operator aten::softplus encountered 2 time(s)\n",
      "Unsupported operator aten::clamp_min encountered 1 time(s)\n",
      "The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.\n",
      "model.encoder.layers.0.self_attn.out_proj, model.encoder.layers.1.self_attn.out_proj\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total FLOPs: 176,352\n"
     ]
    }
   ],
   "source": [
    "wrapped_model = WrappedForecastModel(model)\n",
    "input_tensor = torch.randn(1, 100, 1)  # shape = (batch_size, time_steps, num_features)\n",
    "\n",
    "from fvcore.nn import FlopCountAnalysis\n",
    "flops = FlopCountAnalysis(wrapped_model, input_tensor)\n",
    "print(f\"Total FLOPs: {flops.total():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WrappedForecastModel(\n",
      "  26.02 k, 100.000% Params, 194.05 KMac, 100.000% MACs, \n",
      "  (model): gluonts.torch.model.patch_tst.module.PatchTSTModel(activation='relu', context_length=96, d_model=32, dim_feedforward=32, distr_output=gluonts.torch.distributions.studentT.StudentTOutput(beta=0.0), dropout=0.1, nhead=4, norm_first=False, num_encoder_layers=2, num_feat_dynamic_real=0, padding_patch='end', patch_len=16, prediction_length=1, scaling='mean', stride=8)\n",
      ")\n",
      "MACs: 194.05 KMac, Parameters: 26.02 k\n"
     ]
    }
   ],
   "source": [
    "from ptflops import get_model_complexity_info\n",
    "\n",
    "with torch.no_grad():\n",
    "    macs, params = get_model_complexity_info(wrapped_model, (100, 1), as_strings=True)\n",
    "    print(f\"MACs: {macs}, Parameters: {params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_small = gluonts.torch.model.patch_tst.PatchTSTModel(context_length=8, prediction_length=100, patch_len=1, stride=4,d_model=2, nhead=2, num_encoder_layers=2, scaling=\"mean\",activation=\"relu\", dim_feedforward=32, dropout=0.1, norm_first=False, padding_patch=\"end\", num_feat_dynamic_real=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flops estimation was not finished successfully because of the following exception:\n",
      "<class 'RuntimeError'> : Sizes of tensors must match except in dimension 3. Expected size 104 but got size 100 for tensor number 1 in the list.\n",
      "MACs: None, Parameters: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/ptflops/pytorch_engine.py\", line 68, in get_flops_pytorch\n",
      "    _ = flops_model(batch)\n",
      "        ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1844, in _call_impl\n",
      "    return inner()\n",
      "           ^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1790, in inner\n",
      "    result = forward_call(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/w_/tv9kwn955c59q5gycbr00lzh0000gn/T/ipykernel_59817/1113042157.py\", line 12, in forward\n",
      "    return self.model(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/gluonts/torch/model/patch_tst/module.py\", line 254, in forward\n",
      "    inputs = torch.cat((past_target_patches, expanded_static_feat), dim=-1)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: Sizes of tensors must match except in dimension 3. Expected size 104 but got size 100 for tensor number 1 in the list.\n"
     ]
    }
   ],
   "source": [
    "wrapped_model = WrappedForecastModel(model_small)\n",
    "input_tensor = torch.randn(1, 100, 1)  # shape = (batch_size, time_steps, num_features)\n",
    "\n",
    "with torch.no_grad():\n",
    "    macs, params = get_model_complexity_info(wrapped_model, (100, 100), as_strings=True)\n",
    "    print(f\"MACs: {macs}, Parameters: {params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
